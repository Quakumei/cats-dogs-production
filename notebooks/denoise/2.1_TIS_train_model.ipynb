{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.skoltech.ru/app/data/uploads/sites/19/2018/03/UDNet_CVPR2018.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data\"\n",
    "COMPETITION_FOLDER = \"denoise\"\n",
    "FULL_RAW_DATA_PATH = f\"{DATA_PATH}/raw/{COMPETITION_FOLDER}\"\n",
    "FULL_FINAL_DATA_PATH = f\"{DATA_PATH}/final/{COMPETITION_FOLDER}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# The encoding process\n",
    "input_img = Input(shape=(1024, 1024, 3))\n",
    "\n",
    "############\n",
    "# Encoding #\n",
    "############\n",
    "\n",
    "x = Conv2D(filters = 1, kernel_size = (3, 3), activation='relu', padding='same')(input_img)\n",
    "\n",
    "# Conv1 #\n",
    "x = Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D(pool_size = (2, 2), padding='same')(x)\n",
    "\n",
    "# Conv2 #\n",
    "x = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size = (2, 2), padding='same')(x) \n",
    "\n",
    "# Conv 3 #\n",
    "x = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D(pool_size = (2, 2), padding='same')(x)\n",
    "\n",
    "# Note:\n",
    "# padding is a hyper-arameter for either 'valid' or 'same'. \n",
    "# \"valid\" means \"no padding\". \n",
    "# \"same\" results in padding the input such that the output has the same length as the original input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Decoding #\n",
    "############\n",
    "\n",
    "# DeConv1\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "# DeConv2\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "# Deconv3\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_img_array = np.load(f'{FULL_FINAL_DATA_PATH}/noisy_img_array.npy', allow_pickle=True)\n",
    "gt_img_array = np.load(f'{FULL_FINAL_DATA_PATH}/gt_img_array.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_img_array, gt_img_array, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/final/denoise/denoised_nn_img_array.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m noisy_img_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mFULL_FINAL_DATA_PATH\u001b[39m}\u001b[39;00m\u001b[39m/noisy_img_array.npy\u001b[39m\u001b[39m'\u001b[39m, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m gt_img_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mFULL_FINAL_DATA_PATH\u001b[39m}\u001b[39;00m\u001b[39m/gt_img_array.npy\u001b[39m\u001b[39m'\u001b[39m, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m denoised_img_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mFULL_FINAL_DATA_PATH\u001b[39m}\u001b[39;49;00m\u001b[39m/denoised_nn_img_array.npy\u001b[39;49m\u001b[39m'\u001b[39;49m, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Plot the denoised images side by side with the noisy and ground truth images\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/final/denoise/denoised_nn_img_array.npy'"
     ]
    }
   ],
   "source": [
    "# Load the denoised images\n",
    "noisy_img_array = np.load(f'{FULL_FINAL_DATA_PATH}/noisy_img_array.npy', allow_pickle=True)\n",
    "gt_img_array = np.load(f'{FULL_FINAL_DATA_PATH}/gt_img_array.npy', allow_pickle=True)\n",
    "denoised_img_array = np.load(f'{FULL_FINAL_DATA_PATH}/denoised_nn_img_array.npy', allow_pickle=True)\n",
    "\n",
    "# Plot the denoised images side by side with the noisy and ground truth images\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def plot_denoised_images(noisy_img_array, denoised_img_array, gt_img_array, num_images=5):\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(15, 15))\n",
    "    for i in range(num_images):\n",
    "        idx = random.randint(0, noisy_img_array.shape[0])\n",
    "        axes[i, 0].imshow(noisy_img_array[idx])\n",
    "        axes[i, 0].set_title(\"Noisy Image\")\n",
    "        axes[i, 1].imshow(denoised_img_array[idx])\n",
    "        axes[i, 1].set_title(\"Denoised Image\")\n",
    "        axes[i, 2].imshow(gt_img_array[idx])\n",
    "        axes[i, 2].set_title(\"Ground Truth Image\")\n",
    "    plt.show()\n",
    "\n",
    "plot_denoised_images(noisy_img_array, denoised_img_array, gt_img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитать метрику по PSNR и SSIM\n",
    "\n",
    "# scikit-image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# Calculate the PSNR and SSIM for the denoised images\n",
    "psnr_scores = [psnr(gt_img_array[i], denoised_img_array[i]) for i in tqdm(range(len(gt_img_array)))]\n",
    "\n",
    "# Fix ssim ValueError: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
    "# Time-consuming...\n",
    "ssim_scores = [ssim(gt_img_array[i], denoised_img_array[i], multichannel=True, win_size=3) for i in tqdm(range(len(gt_img_array)))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perforamnce(what:str, psnr_scores, inference_time_in_seconds, ssim_scores=None):\n",
    "    print(f\"{what} performance\")\n",
    "    print(f\"Metrics:\")\n",
    "    print(f\"\\tPSNR: {np.mean(psnr_scores)}\")\n",
    "    print(f\"\\tSSIM: {np.mean(ssim_scores)}\")\n",
    "    print(f\"Inference performance:\")\n",
    "    print(f\"\\tTime per image:\\t{(inference_time_in_seconds)/len(psnr_scores)} seconds\")\n",
    "    print(f\"\\tFPS:\\t\\t{len(psnr_scores)/inference_time_in_seconds} fps\")\n",
    "    print(f\"\\tTotal time:\\t{inference_time_in_seconds} seconds\")\n",
    "    print(f\"\\tImages count:\\t{len(psnr_scores)}\")\n",
    "    print(f\"\\tGPU ENABLED?:\\t{cv2.ocl.useOpenCL()}\")\n",
    "    print(f\"=\"*80)\n",
    "    print(f\"Build info:\\t{cv2.getBuildInformation()}\")\n",
    "\n",
    "print_perforamnce(\"cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\", psnr_scores, inference_time_in_seconds, ssim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in on a small region of the image to see the difference\n",
    "def plot_denoised_images(noisy_img_array, denoised_img_array, gt_img_array, num_images=5):\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(15, 15))\n",
    "    for i in range(num_images):\n",
    "        idx = random.randint(0, noisy_img_array.shape[0])\n",
    "        axes[i, 0].imshow(noisy_img_array[idx][100:200, 100:200])\n",
    "        axes[i, 0].set_title(\"Noisy Image\")\n",
    "        axes[i, 1].imshow(denoised_img_array[idx][100:200, 100:200])\n",
    "        axes[i, 1].set_title(\"Denoised Image\")\n",
    "        axes[i, 2].imshow(gt_img_array[idx][100:200, 100:200])\n",
    "        axes[i, 2].set_title(\"Ground Truth Image\")\n",
    "    plt.show()\n",
    "\n",
    "plot_denoised_images(noisy_img_array, denoised_img_array, gt_img_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de47f5c92c0ee6f12a59a5613ac5feff6aab19ddff207ba0b3964cced08c4ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
